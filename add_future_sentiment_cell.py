# ğŸ”® æ·»åŠ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­
# æ‰©å±•å› å­æ•°æ®ï¼ŒåŠ å…¥æœªæ¥æ”¶ç›Šç‡ç›®æ ‡å˜é‡å’Œæƒ…ç»ªå› å­

# æ·»åŠ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­
if factor_results is not None:
    print(f"ğŸ”® æ­£åœ¨è®¡ç®—æœªæ¥æ”¶ç›Šç‡...")

    try:
        # === è®¡ç®—æœªæ¥æ”¶ç›Šç‡ ===
        print(f"   è®¡ç®—ä¸åŒè·¨åº¦çš„æœªæ¥æ”¶ç›Šç‡...")

        # 1æ—¥æœªæ¥æ”¶ç›Šç‡
        factor_results['future_return_1d'] = factor_results['close'].shift(-1) / factor_results['close'] - 1

        # 3æ—¥æœªæ¥æ”¶ç›Šç‡
        factor_results['future_return_3d'] = factor_results['close'].shift(-3) / factor_results['close'] - 1

        # 5æ—¥æœªæ¥æ”¶ç›Šç‡
        factor_results['future_return_5d'] = factor_results['close'].shift(-5) / factor_results['close'] - 1

        # 10æ—¥æœªæ¥æ”¶ç›Šç‡
        factor_results['future_return_10d'] = factor_results['close'].shift(-10) / factor_results['close'] - 1

        # 20æ—¥æœªæ¥æ”¶ç›Šç‡
        factor_results['future_return_20d'] = factor_results['close'].shift(-20) / factor_results['close'] - 1

        # å¼€ç›˜è¡¨ç°ï¼ˆæ¬¡æ—¥å¼€ç›˜ç›¸å¯¹å½“æ—¥æ”¶ç›˜ï¼‰
        factor_results['open_performance_1d'] = factor_results['open'].shift(-1) / factor_results['close'] - 1

        print(f"âœ… æœªæ¥æ”¶ç›Šç‡è®¡ç®—å®Œæˆ")

        # === åŠ è½½å’Œå¤„ç†æƒ…ç»ªå› å­ ===
        print(f"\nğŸ“° æ­£åœ¨åŠ è½½æƒ…ç»ªå› å­æ•°æ®...")

        import os
        sentiment_file = "D:/projects/q/myQ/scripts/news_scores_result_1y_zijin.csv"

        if os.path.exists(sentiment_file):
            # è¯»å–æƒ…ç»ªæ•°æ®
            sentiment_df = pd.read_csv(sentiment_file, encoding='utf-8-sig')
            print(f"âœ“ åŠ è½½æƒ…ç»ªæ•°æ®: {len(sentiment_df)} æ¡è®°å½•")

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            sentiment_df['date'] = pd.to_datetime(sentiment_df['original_date']).dt.date
            factor_results['date'] = factor_results.index.date

            print(f"âœ“ æƒ…ç»ªæ•°æ®æ—¥æœŸèŒƒå›´: {sentiment_df['date'].min()} åˆ° {sentiment_df['date'].max()}")

            # èšåˆæ—¥åº¦æƒ…ç»ªæ•°æ®
            print(f"   èšåˆæ—¥åº¦æƒ…ç»ªæ•°æ®...")
            daily_sentiment = sentiment_df.groupby('date').agg({
                'overall_score': ['mean', 'std', 'count', 'min', 'max', 'sum'],
                'direct_impact_score': ['mean', 'std'],
                'indirect_impact_score': ['mean', 'std'],
                'certainty': ['mean', 'std', 'min', 'max'],
                'sentiment': lambda x: x.mode()[0] if not x.empty else 'neutral'
            }).round(4)

            # æ‰å¹³åŒ–åˆ—å
            daily_sentiment.columns = [f"{col[0]}_{col[1]}" if col[1] else col[0]
                                     for col in daily_sentiment.columns]
            daily_sentiment = daily_sentiment.reset_index()

            print(f"âœ“ æ—¥åº¦èšåˆ: {len(daily_sentiment)} å¤©")

            # è®¡ç®—æƒ…ç»ªè¡ç”Ÿå› å­
            print(f"   è®¡ç®—æƒ…ç»ªè¡ç”Ÿå› å­...")

            # æŒ‰æ—¥æœŸæ’åº
            daily_sentiment = daily_sentiment.sort_values('date').reset_index(drop=True)

            # 1. åŸºç¡€æƒ…ç»ªå› å­
            daily_sentiment['news_intensity'] = daily_sentiment['overall_score_count']  # æ–°é—»å¼ºåº¦
            daily_sentiment['sentiment_strength'] = abs(daily_sentiment['overall_score_mean'])  # æƒ…ç»ªå¼ºåº¦
            daily_sentiment['weighted_sentiment'] = (daily_sentiment['overall_score_mean'] *
                                                   daily_sentiment['certainty_mean'])  # ç¡®å®šæ€§åŠ æƒæƒ…ç»ª

            # 2. æƒ…ç»ªå˜åŒ–å› å­
            daily_sentiment['sentiment_change_1d'] = daily_sentiment['overall_score_mean'].diff()
            daily_sentiment['sentiment_change_3d'] = daily_sentiment['overall_score_mean'].diff(3)
            daily_sentiment['sentiment_momentum'] = daily_sentiment['overall_score_mean'].rolling(3).mean()
            daily_sentiment['sentiment_volatility'] = daily_sentiment['overall_score_mean'].rolling(5).std()

            # 3. æƒ…ç»ªæå€¼å› å­
            daily_sentiment['sentiment_max_impact'] = daily_sentiment['overall_score_max']
            daily_sentiment['sentiment_min_impact'] = daily_sentiment['overall_score_min']
            daily_sentiment['sentiment_range'] = (daily_sentiment['overall_score_max'] -
                                                daily_sentiment['overall_score_min'])

            # 4. æƒ…ç»ªä¸€è‡´æ€§å› å­
            daily_sentiment['sentiment_consistency'] = (1 - daily_sentiment['overall_score_std'].fillna(0))
            daily_sentiment['certainty_strength'] = daily_sentiment['certainty_mean']

            # 5. æƒ…ç»ªç´¯ç§¯å› å­
            daily_sentiment['sentiment_cumsum_3d'] = daily_sentiment['overall_score_mean'].rolling(3).sum()
            daily_sentiment['sentiment_cumsum_5d'] = daily_sentiment['overall_score_mean'].rolling(5).sum()
            daily_sentiment['sentiment_cumsum_10d'] = daily_sentiment['overall_score_mean'].rolling(10).sum()

            print(f"âœ“ æƒ…ç»ªå› å­è®¡ç®—å®Œæˆ")

            # === åˆå¹¶æƒ…ç»ªå› å­åˆ°ä¸»æ•°æ® ===
            print(f"   åˆå¹¶æƒ…ç»ªå› å­åˆ°ä¸»æ•°æ®...")

            # åˆå¹¶æ•°æ®
            factor_results_with_sentiment = pd.merge(
                factor_results.reset_index(),
                daily_sentiment,
                on='date',
                how='left'
            ).set_index('date')

            # æ›´æ–°factor_results
            factor_results = factor_results_with_sentiment

            # å¡«å……ç¼ºå¤±çš„æƒ…ç»ªæ•°æ®
            sentiment_columns = [col for col in factor_results.columns if any(word in col for word in
                               ['sentiment', 'news', 'certainty', 'impact', 'overall_score'])]

            factor_results[sentiment_columns] = factor_results[sentiment_columns].fillna(0)

            print(f"âœ“ æƒ…ç»ªå› å­åˆå¹¶å®Œæˆ: {len(sentiment_columns)} ä¸ªæƒ…ç»ªå› å­")

            # === è®¡ç®—æ–°é—»-æˆäº¤é‡äº¤äº’å› å­ ===
            print(f"   è®¡ç®—æ–°é—»-æˆäº¤é‡äº¤äº’å› å­...")

            # ç¡®ä¿æœ‰æˆäº¤é‡æ•°æ®
            if 'volume' in factor_results.columns:
                # 1. æˆäº¤é‡ç›¸å…³åŸºç¡€å› å­
                factor_results['volume_ratio_5d'] = factor_results['volume'] / factor_results['volume'].rolling(5).mean()
                factor_results['volume_ratio_20d'] = factor_results['volume'] / factor_results['volume'].rolling(20).mean()
                factor_results['volume_change'] = factor_results['volume'].pct_change()

                # 2. æ–°é—»-æˆäº¤é‡äº¤äº’å› å­
                factor_results['news_vol_interaction_5d'] = (factor_results['overall_score_mean'] *
                                                           factor_results['volume_ratio_5d'])
                factor_results['news_vol_interaction_20d'] = (factor_results['overall_score_mean'] *
                                                            factor_results['volume_ratio_20d'])

                # 3. æƒ…ç»ªå¼ºåº¦è¿‡æ»¤å› å­
                positive_sentiment = np.where(factor_results['overall_score_mean'] > 0,
                                            factor_results['overall_score_mean'], 0)
                negative_sentiment = np.where(factor_results['overall_score_mean'] < 0,
                                            factor_results['overall_score_mean'], 0)
                volume_amplification = np.where(factor_results['volume_ratio_5d'] > 1.2,
                                              factor_results['volume_ratio_5d'], 0)

                factor_results['filtered_positive_news'] = positive_sentiment * volume_amplification
                factor_results['filtered_negative_news'] = negative_sentiment * volume_amplification

                # 4. ç¡®å®šæ€§åŠ æƒçš„æ–°é—»-æˆäº¤é‡å› å­
                factor_results['certainty_vol_factor'] = (factor_results['certainty_mean'] *
                                                        factor_results['volume_ratio_20d'])

                # 5. ç»¼åˆæ–°é—»-æˆäº¤é‡å› å­
                factor_results['comprehensive_news_vol'] = (
                    factor_results['overall_score_mean'] *
                    factor_results['certainty_mean'] *
                    factor_results['volume_ratio_20d'] *
                    np.sign(factor_results['volume_change'])
                )

                print(f"âœ“ æ–°é—»-æˆäº¤é‡äº¤äº’å› å­è®¡ç®—å®Œæˆ")
            else:
                print(f"âš ï¸ ç¼ºå°‘æˆäº¤é‡æ•°æ®ï¼Œè·³è¿‡æ–°é—»-æˆäº¤é‡äº¤äº’å› å­")

        else:
            print(f"âš ï¸ æƒ…ç»ªæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sentiment_file}")
            print(f"   è·³è¿‡æƒ…ç»ªå› å­å¤„ç†ï¼Œä»…è®¡ç®—æœªæ¥æ”¶ç›Šç‡")

        # === ç»Ÿè®¡ç»“æœ ===
        print(f"\nğŸ“Š æ•°æ®æ‰©å±•å®Œæˆ!")
        print(f"   æœ€ç»ˆæ•°æ®å½¢çŠ¶: {factor_results.shape}")

        # ç»Ÿè®¡å„ç±»å› å­
        future_return_columns = [col for col in factor_results.columns if col.startswith('future_return') or col.startswith('open_performance')]
        sentiment_factor_columns = [col for col in factor_results.columns if any(word in col for word in
                                   ['sentiment', 'news', 'certainty', 'impact', 'overall_score'])]
        technical_factor_columns = [col for col in factor_results.columns if col.startswith('factor_')]
        interaction_factor_columns = [col for col in factor_results.columns if any(word in col for word in
                                     ['interaction', 'filtered', 'comprehensive', 'certainty_vol'])]

        print(f"   æŠ€æœ¯å› å­: {len(technical_factor_columns)} ä¸ª")
        print(f"   æœªæ¥æ”¶ç›Šç‡: {len(future_return_columns)} ä¸ª")
        print(f"   æƒ…ç»ªå› å­: {len(sentiment_factor_columns)} ä¸ª")
        print(f"   äº¤äº’å› å­: {len(interaction_factor_columns)} ä¸ª")
        print(f"   æ€»å› å­æ•°: {len(technical_factor_columns) + len(sentiment_factor_columns) + len(interaction_factor_columns)} ä¸ª")

        # æ˜¾ç¤ºå› å­åˆ†ç±»
        if sentiment_factor_columns:
            print(f"\nğŸ“° æƒ…ç»ªå› å­åˆ—è¡¨:")
            sentiment_categories = {
                'åŸºç¡€æƒ…ç»ª': [f for f in sentiment_factor_columns if any(word in f for word in
                            ['overall_score_mean', 'news_intensity', 'sentiment_strength', 'weighted_sentiment'])],
                'æƒ…ç»ªå˜åŒ–': [f for f in sentiment_factor_columns if any(word in f for word in
                            ['change', 'momentum', 'volatility'])],
                'æƒ…ç»ªæå€¼': [f for f in sentiment_factor_columns if any(word in f for word in
                            ['max', 'min', 'range'])],
                'æƒ…ç»ªä¸€è‡´æ€§': [f for f in sentiment_factor_columns if any(word in f for word in
                              ['consistency', 'certainty'])],
                'æƒ…ç»ªç´¯ç§¯': [f for f in sentiment_factor_columns if 'cumsum' in f]
            }

            for category, factors in sentiment_categories.items():
                if factors:
                    print(f"  {category} ({len(factors)}ä¸ª): {factors[:3]}{'...' if len(factors) > 3 else ''}")

        print(f"\nğŸ“ˆ æœªæ¥æ”¶ç›Šç‡åˆ—è¡¨: {future_return_columns}")

        # æ•°æ®è´¨é‡æ£€æŸ¥
        print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        missing_count = factor_results.isnull().sum().sum()
        total_values = factor_results.shape[0] * factor_results.shape[1]
        completeness = (1 - missing_count / total_values) * 100
        print(f"   æ•°æ®å®Œæ•´åº¦: {completeness:.1f}%")
        print(f"   ç¼ºå¤±å€¼: {missing_count} / {total_values}")

        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´
        print(f"   æ—¶é—´èŒƒå›´: {factor_results.index[0]} è‡³ {factor_results.index[-1]}")
        print(f"   æœ‰æ•ˆäº¤æ˜“æ—¥: {len(factor_results)} å¤©")

    except Exception as e:
        print(f"âŒ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

else:
    print("âš ï¸ æ— æ³•è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼šç¼ºå°‘factor_resultsæ•°æ®")