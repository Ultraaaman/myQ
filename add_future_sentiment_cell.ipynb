{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® æ·»åŠ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­\n",
        "æ‰©å±•å› å­æ•°æ®ï¼ŒåŠ å…¥æœªæ¥æ”¶ç›Šç‡ç›®æ ‡å˜é‡å’Œæƒ…ç»ªå› å­"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ·»åŠ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­\n",
        "if factor_results is not None:\n",
        "    print(f\"ğŸ”® æ­£åœ¨è®¡ç®—æœªæ¥æ”¶ç›Šç‡...\")\n",
        "\n",
        "    try:\n",
        "        # === è®¡ç®—æœªæ¥æ”¶ç›Šç‡ ===\n",
        "        print(f\"   è®¡ç®—ä¸åŒè·¨åº¦çš„æœªæ¥æ”¶ç›Šç‡...\")\n",
        "\n",
        "        # 1æ—¥æœªæ¥æ”¶ç›Šç‡\n",
        "        factor_results['future_return_1d'] = factor_results['close'].shift(-1) / factor_results['close'] - 1\n",
        "\n",
        "        # 3æ—¥æœªæ¥æ”¶ç›Šç‡\n",
        "        factor_results['future_return_3d'] = factor_results['close'].shift(-3) / factor_results['close'] - 1\n",
        "\n",
        "        # 5æ—¥æœªæ¥æ”¶ç›Šç‡\n",
        "        factor_results['future_return_5d'] = factor_results['close'].shift(-5) / factor_results['close'] - 1\n",
        "\n",
        "        # 10æ—¥æœªæ¥æ”¶ç›Šç‡\n",
        "        factor_results['future_return_10d'] = factor_results['close'].shift(-10) / factor_results['close'] - 1\n",
        "\n",
        "        # 20æ—¥æœªæ¥æ”¶ç›Šç‡\n",
        "        factor_results['future_return_20d'] = factor_results['close'].shift(-20) / factor_results['close'] - 1\n",
        "\n",
        "        # å¼€ç›˜è¡¨ç°ï¼ˆæ¬¡æ—¥å¼€ç›˜ç›¸å¯¹å½“æ—¥æ”¶ç›˜ï¼‰\n",
        "        factor_results['open_performance_1d'] = factor_results['open'].shift(-1) / factor_results['close'] - 1\n",
        "\n",
        "        print(f\"âœ… æœªæ¥æ”¶ç›Šç‡è®¡ç®—å®Œæˆ\")\n",
        "\n",
        "        # === åŠ è½½å’Œå¤„ç†æƒ…ç»ªå› å­ ===\n",
        "        print(f\"\\nğŸ“° æ­£åœ¨åŠ è½½æƒ…ç»ªå› å­æ•°æ®...\")\n",
        "\n",
        "        import os\n",
        "        sentiment_file = \"D:/projects/q/myQ/scripts/news_scores_result_1y_zijin.csv\"\n",
        "\n",
        "        if os.path.exists(sentiment_file):\n",
        "            # è¯»å–æƒ…ç»ªæ•°æ®\n",
        "            sentiment_df = pd.read_csv(sentiment_file, encoding='utf-8-sig')\n",
        "            print(f\"âœ“ åŠ è½½æƒ…ç»ªæ•°æ®: {len(sentiment_df)} æ¡è®°å½•\")\n",
        "\n",
        "            # è½¬æ¢æ—¥æœŸæ ¼å¼\n",
        "            sentiment_df['date'] = pd.to_datetime(sentiment_df['original_date']).dt.date\n",
        "            factor_results['date'] = factor_results.index.date\n",
        "\n",
        "            print(f\"âœ“ æƒ…ç»ªæ•°æ®æ—¥æœŸèŒƒå›´: {sentiment_df['date'].min()} åˆ° {sentiment_df['date'].max()}\")\n",
        "\n",
        "            # èšåˆæ—¥åº¦æƒ…ç»ªæ•°æ®\n",
        "            print(f\"   èšåˆæ—¥åº¦æƒ…ç»ªæ•°æ®...\")\n",
        "            daily_sentiment = sentiment_df.groupby('date').agg({\n",
        "                'overall_score': ['mean', 'std', 'count', 'min', 'max', 'sum'],\n",
        "                'direct_impact_score': ['mean', 'std'],\n",
        "                'indirect_impact_score': ['mean', 'std'],\n",
        "                'certainty': ['mean', 'std', 'min', 'max'],\n",
        "                'sentiment': lambda x: x.mode()[0] if not x.empty else 'neutral'\n",
        "            }).round(4)\n",
        "\n",
        "            # æ‰å¹³åŒ–åˆ—å\n",
        "            daily_sentiment.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
        "                                     for col in daily_sentiment.columns]\n",
        "            daily_sentiment = daily_sentiment.reset_index()\n",
        "\n",
        "            print(f\"âœ“ æ—¥åº¦èšåˆ: {len(daily_sentiment)} å¤©\")\n",
        "\n",
        "            # è®¡ç®—æƒ…ç»ªè¡ç”Ÿå› å­\n",
        "            print(f\"   è®¡ç®—æƒ…ç»ªè¡ç”Ÿå› å­...\")\n",
        "\n",
        "            # æŒ‰æ—¥æœŸæ’åº\n",
        "            daily_sentiment = daily_sentiment.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "            # 1. åŸºç¡€æƒ…ç»ªå› å­\n",
        "            daily_sentiment['news_intensity'] = daily_sentiment['overall_score_count']  # æ–°é—»å¼ºåº¦\n",
        "            daily_sentiment['sentiment_strength'] = abs(daily_sentiment['overall_score_mean'])  # æƒ…ç»ªå¼ºåº¦\n",
        "            daily_sentiment['weighted_sentiment'] = (daily_sentiment['overall_score_mean'] *\n",
        "                                                   daily_sentiment['certainty_mean'])  # ç¡®å®šæ€§åŠ æƒæƒ…ç»ª\n",
        "\n",
        "            # 2. æƒ…ç»ªå˜åŒ–å› å­\n",
        "            daily_sentiment['sentiment_change_1d'] = daily_sentiment['overall_score_mean'].diff()\n",
        "            daily_sentiment['sentiment_change_3d'] = daily_sentiment['overall_score_mean'].diff(3)\n",
        "            daily_sentiment['sentiment_momentum'] = daily_sentiment['overall_score_mean'].rolling(3).mean()\n",
        "            daily_sentiment['sentiment_volatility'] = daily_sentiment['overall_score_mean'].rolling(5).std()\n",
        "\n",
        "            # 3. æƒ…ç»ªæå€¼å› å­\n",
        "            daily_sentiment['sentiment_max_impact'] = daily_sentiment['overall_score_max']\n",
        "            daily_sentiment['sentiment_min_impact'] = daily_sentiment['overall_score_min']\n",
        "            daily_sentiment['sentiment_range'] = (daily_sentiment['overall_score_max'] -\n",
        "                                                daily_sentiment['overall_score_min'])\n",
        "\n",
        "            # 4. æƒ…ç»ªä¸€è‡´æ€§å› å­\n",
        "            daily_sentiment['sentiment_consistency'] = (1 - daily_sentiment['overall_score_std'].fillna(0))\n",
        "            daily_sentiment['certainty_strength'] = daily_sentiment['certainty_mean']\n",
        "\n",
        "            # 5. æƒ…ç»ªç´¯ç§¯å› å­\n",
        "            daily_sentiment['sentiment_cumsum_3d'] = daily_sentiment['overall_score_mean'].rolling(3).sum()\n",
        "            daily_sentiment['sentiment_cumsum_5d'] = daily_sentiment['overall_score_mean'].rolling(5).sum()\n",
        "            daily_sentiment['sentiment_cumsum_10d'] = daily_sentiment['overall_score_mean'].rolling(10).sum()\n",
        "\n",
        "            print(f\"âœ“ æƒ…ç»ªå› å­è®¡ç®—å®Œæˆ\")\n",
        "\n",
        "            # === åˆå¹¶æƒ…ç»ªå› å­åˆ°ä¸»æ•°æ® ===\n",
        "            print(f\"   åˆå¹¶æƒ…ç»ªå› å­åˆ°ä¸»æ•°æ®...\")\n",
        "\n",
        "            # åˆå¹¶æ•°æ®\n",
        "            factor_results_with_sentiment = pd.merge(\n",
        "                factor_results.reset_index(),\n",
        "                daily_sentiment,\n",
        "                on='date',\n",
        "                how='left'\n",
        "            ).set_index('date')\n",
        "\n",
        "            # æ›´æ–°factor_results\n",
        "            factor_results = factor_results_with_sentiment\n",
        "\n",
        "            # å¡«å……ç¼ºå¤±çš„æƒ…ç»ªæ•°æ®\n",
        "            sentiment_columns = [col for col in factor_results.columns if any(word in col for word in\n",
        "                               ['sentiment', 'news', 'certainty', 'impact', 'overall_score'])]\n",
        "\n",
        "            factor_results[sentiment_columns] = factor_results[sentiment_columns].fillna(0)\n",
        "\n",
        "            print(f\"âœ“ æƒ…ç»ªå› å­åˆå¹¶å®Œæˆ: {len(sentiment_columns)} ä¸ªæƒ…ç»ªå› å­\")\n",
        "\n",
        "            # === è®¡ç®—æ–°é—»-æˆäº¤é‡äº¤äº’å› å­ ===\n",
        "            print(f\"   è®¡ç®—æ–°é—»-æˆäº¤é‡äº¤äº’å› å­...\")\n",
        "\n",
        "            # ç¡®ä¿æœ‰æˆäº¤é‡æ•°æ®\n",
        "            if 'volume' in factor_results.columns:\n",
        "                # 1. æˆäº¤é‡ç›¸å…³åŸºç¡€å› å­\n",
        "                factor_results['volume_ratio_5d'] = factor_results['volume'] / factor_results['volume'].rolling(5).mean()\n",
        "                factor_results['volume_ratio_20d'] = factor_results['volume'] / factor_results['volume'].rolling(20).mean()\n",
        "                factor_results['volume_change'] = factor_results['volume'].pct_change()\n",
        "\n",
        "                # 2. æ–°é—»-æˆäº¤é‡äº¤äº’å› å­\n",
        "                factor_results['news_vol_interaction_5d'] = (factor_results['overall_score_mean'] *\n",
        "                                                           factor_results['volume_ratio_5d'])\n",
        "                factor_results['news_vol_interaction_20d'] = (factor_results['overall_score_mean'] *\n",
        "                                                            factor_results['volume_ratio_20d'])\n",
        "\n",
        "                # 3. æƒ…ç»ªå¼ºåº¦è¿‡æ»¤å› å­\n",
        "                positive_sentiment = np.where(factor_results['overall_score_mean'] > 0,\n",
        "                                            factor_results['overall_score_mean'], 0)\n",
        "                negative_sentiment = np.where(factor_results['overall_score_mean'] < 0,\n",
        "                                            factor_results['overall_score_mean'], 0)\n",
        "                volume_amplification = np.where(factor_results['volume_ratio_5d'] > 1.2,\n",
        "                                              factor_results['volume_ratio_5d'], 0)\n",
        "\n",
        "                factor_results['filtered_positive_news'] = positive_sentiment * volume_amplification\n",
        "                factor_results['filtered_negative_news'] = negative_sentiment * volume_amplification\n",
        "\n",
        "                # 4. ç¡®å®šæ€§åŠ æƒçš„æ–°é—»-æˆäº¤é‡å› å­\n",
        "                factor_results['certainty_vol_factor'] = (factor_results['certainty_mean'] *\n",
        "                                                        factor_results['volume_ratio_20d'])\n",
        "\n",
        "                # 5. ç»¼åˆæ–°é—»-æˆäº¤é‡å› å­\n",
        "                factor_results['comprehensive_news_vol'] = (\n",
        "                    factor_results['overall_score_mean'] *\n",
        "                    factor_results['certainty_mean'] *\n",
        "                    factor_results['volume_ratio_20d'] *\n",
        "                    np.sign(factor_results['volume_change'])\n",
        "                )\n",
        "\n",
        "                print(f\"âœ“ æ–°é—»-æˆäº¤é‡äº¤äº’å› å­è®¡ç®—å®Œæˆ\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ ç¼ºå°‘æˆäº¤é‡æ•°æ®ï¼Œè·³è¿‡æ–°é—»-æˆäº¤é‡äº¤äº’å› å­\")\n",
        "\n",
        "        else:\n",
        "            print(f\"âš ï¸ æƒ…ç»ªæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sentiment_file}\")\n",
        "            print(f\"   è·³è¿‡æƒ…ç»ªå› å­å¤„ç†ï¼Œä»…è®¡ç®—æœªæ¥æ”¶ç›Šç‡\")\n",
        "\n",
        "        # === ç»Ÿè®¡ç»“æœ ===\n",
        "        print(f\"\\nğŸ“Š æ•°æ®æ‰©å±•å®Œæˆ!\")\n",
        "        print(f\"   æœ€ç»ˆæ•°æ®å½¢çŠ¶: {factor_results.shape}\")\n",
        "\n",
        "        # ç»Ÿè®¡å„ç±»å› å­\n",
        "        future_return_columns = [col for col in factor_results.columns if col.startswith('future_return') or col.startswith('open_performance')]\n",
        "        sentiment_factor_columns = [col for col in factor_results.columns if any(word in col for word in\n",
        "                                   ['sentiment', 'news', 'certainty', 'impact', 'overall_score'])]\n",
        "        technical_factor_columns = [col for col in factor_results.columns if col.startswith('factor_')]\n",
        "        interaction_factor_columns = [col for col in factor_results.columns if any(word in col for word in\n",
        "                                     ['interaction', 'filtered', 'comprehensive', 'certainty_vol'])]\n",
        "\n",
        "        print(f\"   æŠ€æœ¯å› å­: {len(technical_factor_columns)} ä¸ª\")\n",
        "        print(f\"   æœªæ¥æ”¶ç›Šç‡: {len(future_return_columns)} ä¸ª\")\n",
        "        print(f\"   æƒ…ç»ªå› å­: {len(sentiment_factor_columns)} ä¸ª\")\n",
        "        print(f\"   äº¤äº’å› å­: {len(interaction_factor_columns)} ä¸ª\")\n",
        "        print(f\"   æ€»å› å­æ•°: {len(technical_factor_columns) + len(sentiment_factor_columns) + len(interaction_factor_columns)} ä¸ª\")\n",
        "\n",
        "        # æ˜¾ç¤ºå› å­åˆ†ç±»\n",
        "        if sentiment_factor_columns:\n",
        "            print(f\"\\nğŸ“° æƒ…ç»ªå› å­åˆ—è¡¨:\")\n",
        "            sentiment_categories = {\n",
        "                'åŸºç¡€æƒ…ç»ª': [f for f in sentiment_factor_columns if any(word in f for word in\n",
        "                            ['overall_score_mean', 'news_intensity', 'sentiment_strength', 'weighted_sentiment'])],\n",
        "                'æƒ…ç»ªå˜åŒ–': [f for f in sentiment_factor_columns if any(word in f for word in\n",
        "                            ['change', 'momentum', 'volatility'])],\n",
        "                'æƒ…ç»ªæå€¼': [f for f in sentiment_factor_columns if any(word in f for word in\n",
        "                            ['max', 'min', 'range'])],\n",
        "                'æƒ…ç»ªä¸€è‡´æ€§': [f for f in sentiment_factor_columns if any(word in f for word in\n",
        "                              ['consistency', 'certainty'])],\n",
        "                'æƒ…ç»ªç´¯ç§¯': [f for f in sentiment_factor_columns if 'cumsum' in f]\n",
        "            }\n",
        "\n",
        "            for category, factors in sentiment_categories.items():\n",
        "                if factors:\n",
        "                    print(f\"  {category} ({len(factors)}ä¸ª): {factors[:3]}{'...' if len(factors) > 3 else ''}\")\n",
        "\n",
        "        print(f\"\\nğŸ“ˆ æœªæ¥æ”¶ç›Šç‡åˆ—è¡¨: {future_return_columns}\")\n",
        "\n",
        "        # æ•°æ®è´¨é‡æ£€æŸ¥\n",
        "        print(f\"\\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
        "        missing_count = factor_results.isnull().sum().sum()\n",
        "        total_values = factor_results.shape[0] * factor_results.shape[1]\n",
        "        completeness = (1 - missing_count / total_values) * 100\n",
        "        print(f\"   æ•°æ®å®Œæ•´åº¦: {completeness:.1f}%\")\n",
        "        print(f\"   ç¼ºå¤±å€¼: {missing_count} / {total_values}\")\n",
        "\n",
        "        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´\n",
        "        print(f\"   æ—¶é—´èŒƒå›´: {factor_results.index[0]} è‡³ {factor_results.index[-1]}\")\n",
        "        print(f\"   æœ‰æ•ˆäº¤æ˜“æ—¥: {len(factor_results)} å¤©\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æœªæ¥æ”¶ç›Šç‡å’Œæƒ…ç»ªå› å­è®¡ç®—å¤±è´¥: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ æ— æ³•è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼šç¼ºå°‘factor_resultsæ•°æ®\")"
      ]
    }
  ],\n",
  "metadata": {\n",
    "kernelspec": {\n",
      "display_name": "Python 3",\n",
      "language": "python",\n",
      "name": "python3"\n",
    },\n",
    "language_info": {\n",
      "name": "python",\n",
      "version": "3.8.0"\n",
    }\n",
  },\n",
  "nbformat": 4,\n",
  "nbformat_minor": 4\n",
}