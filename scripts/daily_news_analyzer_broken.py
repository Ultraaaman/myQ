#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æ–°é—»åˆ†æè„šæœ¬ï¼ˆä¿®å¤æ—¥æœŸæ—¶é—´æ ¼å¼ç‰ˆæœ¬ï¼‰
"""

import tushare as ts
import pandas as pd
import json
import requests
import os
import time
import random
from datetime import datetime, timedelta
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DailyNewsAnalyzer:
    def __init__(self, tushare_token, openrouter_api_key):
        """åˆå§‹åŒ–æ–°é—»åˆ†æå™¨ - è°ƒè¯•ç‰ˆ"""
        print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–åˆ†æå™¨...")

        # åˆå§‹åŒ–API
        print(f"ğŸ”§ åˆå§‹åŒ–Tushare API...")
        self.ts_pro = ts.pro_api(tushare_token)
        print(f"âœ… Tushare APIåˆå§‹åŒ–å®Œæˆ")

        self.api_key = openrouter_api_key
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {openrouter_api_key}",
            "Content-Type": "application/json",
        }

        # è®¾ç½®æ–‡ä»¶è·¯å¾„
        print(f"ğŸ”§ è®¾ç½®æ–‡ä»¶è·¯å¾„...")
        self.base_dir = Path("D:/projects/q/myQ")
        self.output_dir = self.base_dir / "output" / "daily_analysis"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… è¾“å‡ºç›®å½•: {self.output_dir}")

        # åŠ è½½è‚¡ç¥¨æ± 
        print(f"ğŸ”§ åŠ è½½è‚¡ç¥¨æ± ...")
        self.stock_pool = self._load_stock_pool()
        print(f"âœ… è‚¡ç¥¨æ± åŠ è½½å®Œæˆ: {len(self.stock_pool)} åªè‚¡ç¥¨")

        print(f"ğŸ”§ æå–å…³é”®è¯...")
        self.stock_keywords = self._extract_keywords()
        print(f"âœ… å…³é”®è¯æå–å®Œæˆ: {len(self.stock_keywords)} ä¸ªè‚¡ç¥¨")

    def _load_stock_pool(self):
        """åŠ è½½è‚¡ç¥¨æ±  - è°ƒè¯•ç‰ˆ"""
        stock_pool_path = self.base_dir / "config" / "stock_pool.json"
        print(f"ğŸ“ è¯»å–è‚¡ç¥¨æ± æ–‡ä»¶: {stock_pool_path}")

        with open(stock_pool_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"ğŸ“Š åŸå§‹JSONæ•°æ®é”®: {list(data.keys())}")

        # æ”¯æŒä¸åŒçš„JSONæ ¼å¼
        if 'stocks' in data:
            stocks = data['stocks']
            print(f"âœ… ä½¿ç”¨ 'stocks' é”®")
        elif 'stock_database' in data:
            stocks = data['stock_database']
            print(f"âœ… ä½¿ç”¨ 'stock_database' é”®")
        else:
            stocks = data if isinstance(data, list) else []
            print(f"âœ… æ•°æ®æœ¬èº«å°±æ˜¯åˆ—è¡¨")

        print(f"ğŸ“Š æœ€ç»ˆè‚¡ç¥¨æ•°é‡: {len(stocks)}")
        return stocks

    def _extract_keywords(self):
        """æå–å…³é”®è¯ - è°ƒè¯•ç‰ˆ"""
        keywords = {}

        for i, stock in enumerate(self.stock_pool):
            stock_keywords = []
            stock_keywords.append(stock['stock_name'])
            stock_keywords.append(stock['stock_code'])

            # æå–è¡Œä¸šå’Œä¸»è¥ä¸šåŠ¡å…³é”®è¯
            if 'industry' in stock:
                stock_keywords.extend(stock['industry'].split())
            if 'main_business' in stock:
                business_words = stock['main_business'].replace('ï¼Œ', ' ').replace('ã€', ' ').split()
                business_words = [w for w in business_words if len(w) >= 2][:5]
                stock_keywords.extend(business_words)

            # å»é‡
            keywords[stock['stock_code']] = list(set(stock_keywords))

            # æ˜¾ç¤ºå‰3ä¸ªè‚¡ç¥¨çš„å…³é”®è¯ç”¨äºè°ƒè¯•
            if i < 3:
                print(f"  {stock['stock_name']} ({stock['stock_code']}): {keywords[stock['stock_code']]}")

        return keywords

    def get_daily_news(self, target_date=None):
        """è·å–å½“æ—¥æ–°é—» - ä¿®å¤æ—¥æœŸæ—¶é—´æ ¼å¼ç‰ˆ"""
        if target_date is None:
            start_date = datetime.now().strftime('%Y-%m-%d 09:00:00')
            end_date = datetime.now().strftime('%Y-%m-%d 18:00:00')
        else:
            # ä¿®æ­£ï¼šä½¿ç”¨å®Œæ•´çš„æ—¥æœŸæ—¶é—´æ ¼å¼ YYYY-MM-DD HH:MM:SS
            start_date = f"{target_date} 09:00:00"
            end_date = f"{target_date} 18:00:00"

        print(f"ğŸ“° å‡†å¤‡è·å–æ–°é—»æ•°æ®...")
        print(f"   - å¼€å§‹æ—¶é—´: {start_date}")
        print(f"   - ç»“æŸæ—¶é—´: {end_date}")
        print(f"   - APIå¯¹è±¡: {type(self.ts_pro)}")

        # ç›´æ¥è°ƒç”¨APIï¼Œä¸ä½¿ç”¨try-except
        print(f"ğŸ”§ è°ƒç”¨ self.ts_pro.news()...")
        news_df = self.ts_pro.news(
            src='sina',
            start_date=start_date,
            end_date=end_date
        )

        print(f"ğŸ“Š APIè¿”å›ç»“æœ:")
        print(f"   - æ•°æ®ç±»å‹: {type(news_df)}")
        print(f"   - æ˜¯å¦ä¸ºç©º: {news_df.empty if hasattr(news_df, 'empty') else 'N/A'}")
        print(f"   - æ•°æ®å½¢çŠ¶: {news_df.shape if hasattr(news_df, 'shape') else 'N/A'}")

        if hasattr(news_df, 'columns'):
            print(f"   - åˆ—å: {list(news_df.columns)}")

        if hasattr(news_df, 'empty') and not news_df.empty:
            print(f"   - å‰3è¡Œæ•°æ®:")
            print(news_df.head(3))

        return news_df

    def match_news_to_stocks(self, news_df):
        """åŒ¹é…æ–°é—»åˆ°è‚¡ç¥¨ - è°ƒè¯•ç‰ˆ"""
        if news_df.empty:
            print("âš ï¸ æ–°é—»æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡åŒ¹é…")
            return news_df

        print(f"ğŸ” å¼€å§‹åŒ¹é…æ–°é—»åˆ°è‚¡ç¥¨...")
        matched_records = []

        for i, (_, news_row) in enumerate(news_df.iterrows()):
            if i < 2:  # åªå¤„ç†å‰2æ¡æ–°é—»ç”¨äºè°ƒè¯•
                print(f"  å¤„ç†ç¬¬ {i+1} æ¡æ–°é—»:")
                print(f"    æ ‡é¢˜: {news_row['title'][:50]}...")

            news_title = str(news_row['title']).lower()
            news_content = str(news_row.get('content', '')).lower()
            full_text = f"{news_title} {news_content}"

            # åŒ¹é…è‚¡ç¥¨
            matched_stocks = []
            for stock in self.stock_pool:
                stock_code = stock['stock_code']
                keywords = self.stock_keywords.get(stock_code, [])

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…
                matched = False
                matched_keyword = None
                for keyword in keywords:
                    if len(keyword) >= 2 and keyword.lower() in full_text:
                        matched = True
                        matched_keyword = keyword
                        break

                if matched:
                    matched_stocks.append((stock['stock_name'], matched_keyword))
                    record = news_row.to_dict()
                    record.update(stock)
                    matched_records.append(record)

            if i < 2 and matched_stocks:  # è°ƒè¯•ä¿¡æ¯
                print(f"    åŒ¹é…åˆ°è‚¡ç¥¨: {matched_stocks}")

        matched_df = pd.DataFrame(matched_records)
        print(f"ğŸ¯ åŒ¹é…å®Œæˆï¼Œæ‰¾åˆ° {len(matched_df)} æ¡è‚¡ç¥¨ç›¸å…³æ–°é—»")

        return matched_df

def main():
    """ç®€åŒ–çš„ä¸»å‡½æ•°ç”¨äºè°ƒè¯•"""
    print("ğŸ§ª å¼€å§‹è°ƒè¯•æµ‹è¯•...")

    # å¯¼å…¥é…ç½®
    import sys
    sys.path.append(str(Path(__file__).parent.parent / "config"))
    from api_config import TUSHARE_TOKEN, OPENROUTER_API_KEY

    print(f"ğŸ”‘ é…ç½®æ£€æŸ¥:")
    print(f"   - Tushare Token: {'å·²é…ç½®' if TUSHARE_TOKEN != 'your_tushare_token_here' else 'æœªé…ç½®'}")
    print(f"   - OpenRouter Key: {'å·²é…ç½®' if OPENROUTER_API_KEY != 'your_openrouter_api_key_here' else 'æœªé…ç½®'}")

    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = DailyNewsAnalyzer(TUSHARE_TOKEN, OPENROUTER_API_KEY)

    # æµ‹è¯•æ–°é—»è·å–
    print(f"\nğŸ“° æµ‹è¯•æ–°é—»è·å–...")
    news_df = analyzer.get_daily_news("2024-12-20")

    # å¦‚æœæœ‰æ–°é—»ï¼Œæµ‹è¯•åŒ¹é…
    if hasattr(news_df, 'empty') and not news_df.empty:
        print(f"\nğŸ” æµ‹è¯•æ–°é—»åŒ¹é…...")
        matched_df = analyzer.match_news_to_stocks(news_df)
    else:
        print(f"âŒ æ²¡æœ‰æ–°é—»æ•°æ®ï¼Œè·³è¿‡åŒ¹é…æµ‹è¯•")

    print(f"\nğŸ‰ è°ƒè¯•æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()