#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¶é—´æ®µæ–°é—»æŠ“å–è„šæœ¬ï¼ˆç²¾ç®€ç‰ˆï¼‰

åŠŸèƒ½è¯´æ˜ï¼š
- æ”¯æŒæŒ‡å®šæ—¥æœŸèŒƒå›´æŠ“å–æ–°é—»ï¼ˆä»å¼€å§‹æ—¥æœŸåˆ°ç»“æŸæ—¥æœŸï¼‰
- è‡ªåŠ¨åŒ¹é…è‚¡ç¥¨æ± ä¸­çš„è‚¡ç¥¨
- ä»…æŠ“å–å’Œæ•´ç†æ–°é—»æ•°æ®ï¼Œè¾“å‡ºå•ä¸ªCSVæ±‡æ€»æ–‡ä»¶
- è‡ªåŠ¨è¿‡æ»¤å‘¨æœ«ï¼Œåªå¤„ç†å·¥ä½œæ—¥

ä½¿ç”¨æ–¹æ³•ï¼š
    python period_news_fetcher.py --start_date 2025-09-01 --end_date 2025-09-30

å‚æ•°è¯´æ˜ï¼š
    --start_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)
    --end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)

è¾“å‡ºæ–‡ä»¶ï¼š
    news_YYYYMMDD_YYYYMMDD.csv - æ–°é—»æ±‡æ€»æ–‡ä»¶
"""

import tushare as ts
import pandas as pd
import json
import os
from datetime import datetime, timedelta
import logging
from pathlib import Path
import argparse

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class PeriodNewsFetcher:
    def __init__(self, tushare_token):
        """åˆå§‹åŒ–æ–°é—»æŠ“å–å™¨"""
        print(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æ–°é—»æŠ“å–å™¨...")

        # åˆå§‹åŒ–Tushare API
        print(f"ğŸ”§ åˆå§‹åŒ–Tushare API...")
        self.ts_pro = ts.pro_api(tushare_token)
        print(f"âœ… Tushare APIåˆå§‹åŒ–å®Œæˆ")

        # è®¾ç½®æ–‡ä»¶è·¯å¾„
        print(f"ğŸ”§ è®¾ç½®æ–‡ä»¶è·¯å¾„...")
        self.base_dir = Path("D:/projects/q/myQ")
        self.output_dir = self.base_dir / "output" / "period_news"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… è¾“å‡ºç›®å½•: {self.output_dir}")

        # åŠ è½½è‚¡ç¥¨æ± 
        print(f"ğŸ”§ åŠ è½½è‚¡ç¥¨æ± ...")
        self.stock_pool = self._load_stock_pool()
        print(f"âœ… è‚¡ç¥¨æ± åŠ è½½å®Œæˆ: {len(self.stock_pool)} åªè‚¡ç¥¨")

        # æå–å…³é”®è¯
        print(f"ğŸ”§ æå–å…³é”®è¯...")
        self.stock_keywords = self._extract_keywords()
        print(f"âœ… å…³é”®è¯æå–å®Œæˆ: {len(self.stock_keywords)} ä¸ªè‚¡ç¥¨")

    def _load_stock_pool(self):
        """åŠ è½½è‚¡ç¥¨æ± """
        stock_pool_path = self.base_dir / "config" / "stock_pool.json"
        print(f"ğŸ“ è¯»å–è‚¡ç¥¨æ± æ–‡ä»¶: {stock_pool_path}")

        with open(stock_pool_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # æ”¯æŒä¸åŒçš„JSONæ ¼å¼
        if 'stocks' in data:
            stocks = data['stocks']
        elif 'stock_database' in data:
            stocks = data['stock_database']
        else:
            stocks = data if isinstance(data, list) else []

        print(f"ğŸ“Š æœ€ç»ˆè‚¡ç¥¨æ•°é‡: {len(stocks)}")
        return stocks

    def _extract_keywords(self):
        """æå–è‚¡ç¥¨å…³é”®è¯"""
        keywords = {}

        for stock in self.stock_pool:
            stock_keywords = []
            stock_keywords.append(stock['stock_name'])
            stock_keywords.append(stock['stock_code'])

            # å»é‡
            keywords[stock['stock_code']] = list(set(stock_keywords))

        return keywords

    def get_news_by_date(self, target_date):
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ–°é—»"""
        start_datetime = f"{target_date} 09:00:00"
        end_datetime = f"{target_date} 18:00:00"

        try:
            news_df = self.ts_pro.news(
                src='sina',
                start_date=start_datetime,
                end_date=end_datetime
            )

            if news_df is not None and not news_df.empty:
                return news_df
            else:
                return pd.DataFrame()

        except Exception as e:
            return pd.DataFrame()

    def match_news_to_stocks(self, news_df, date_str=None):
        """åŒ¹é…æ–°é—»åˆ°è‚¡ç¥¨"""
        if news_df.empty:
            return pd.DataFrame()

        matched_records = []

        for _, news_row in news_df.iterrows():
            # å®‰å…¨è·å–å­—æ®µå€¼
            title = news_row.get('title') or news_row.get('Title') or ''
            content = news_row.get('content') or news_row.get('Content') or ''

            news_title = str(title).lower() if title else ''
            news_content = str(content).lower() if content else ''
            full_text = f"{news_title} {news_content}"

            # åŒ¹é…è‚¡ç¥¨
            for stock in self.stock_pool:
                stock_code = stock['stock_code']
                keywords = self.stock_keywords.get(stock_code, [])

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…
                matched = False
                matched_keyword = None
                for keyword in keywords:
                    if len(keyword) >= 2 and keyword.lower() in full_text:
                        matched = True
                        matched_keyword = keyword
                        break

                if matched:
                    record = news_row.to_dict()
                    record.update({
                        'stock_code': stock['stock_code'],
                        'stock_name': stock['stock_name'],
                        'industry': stock.get('industry', ''),
                        'matched_keyword': matched_keyword
                    })

                    # æ·»åŠ æŠ“å–æ—¥æœŸï¼ˆå¦‚æœæä¾›ï¼‰
                    if date_str:
                        record['fetch_date'] = date_str

                    matched_records.append(record)

        matched_df = pd.DataFrame(matched_records)
        return matched_df

    def generate_date_range(self, start_date, end_date):
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´åˆ—è¡¨ï¼ˆä»…å·¥ä½œæ—¥ï¼‰"""
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')

        date_list = []
        current = start

        while current <= end:
            # è¿‡æ»¤å‘¨æœ« (0=å‘¨ä¸€, 6=å‘¨æ—¥)
            if current.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                date_list.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)

        return date_list

    def fetch_period_news(self, start_date, end_date):
        """
        æŠ“å–æ—¶é—´æ®µå†…çš„æ–°é—»

        å‚æ•°:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        """
        print(f"\nğŸš€ å¼€å§‹æŠ“å–æ—¶é—´æ®µæ–°é—»")
        print(f"   å¼€å§‹æ—¥æœŸ: {start_date}")
        print(f"   ç»“æŸæ—¥æœŸ: {end_date}")

        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        date_list = self.generate_date_range(start_date, end_date)
        print(f"\nğŸ“… å…±éœ€æŠ“å– {len(date_list)} ä¸ªäº¤æ˜“æ—¥")

        # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        summary_filename = self.output_dir / f"news_{start_date.replace('-', '')}_{end_date.replace('-', '')}.csv"
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {summary_filename}\n")

        total_matched = 0
        first_write = True

        # é€æ—¥æŠ“å–å¹¶ç«‹å³å†™å…¥
        for i, date_str in enumerate(date_list, 1):
            print(f"å¤„ç†è¿›åº¦: [{i}/{len(date_list)}] {date_str}", end=" ")

            # è·å–å½“æ—¥æ–°é—»
            news_df = self.get_news_by_date(date_str)

            if news_df.empty:
                print("- æ— æ•°æ®")
                continue

            # åŒ¹é…è‚¡ç¥¨
            matched_df = self.match_news_to_stocks(news_df, date_str)

            # ç«‹å³å†™å…¥CSVæ–‡ä»¶
            if not matched_df.empty:
                if first_write:
                    # ç¬¬ä¸€æ¬¡å†™å…¥ï¼Œåˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
                    matched_df.to_csv(summary_filename, mode='w', index=False, encoding='utf-8-sig')
                    first_write = False
                else:
                    # åç»­å†™å…¥ï¼Œè¿½åŠ æ¨¡å¼ï¼Œä¸å†™è¡¨å¤´
                    matched_df.to_csv(summary_filename, mode='a', header=False, index=False, encoding='utf-8-sig')

                total_matched += len(matched_df)
                print(f"- åŒ¹é… {len(matched_df)} æ¡ âœ“")
            else:
                print("- æ— åŒ¹é…")

            # é¿å…APIé™åˆ¶ï¼Œæ·»åŠ å»¶è¿Ÿ
            if i < len(date_list):
                import time
                time.sleep(1)

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        if total_matched > 0:
            print(f"\nğŸ‰ æŠ“å–å®Œæˆï¼")
            print(f"ğŸ’¾ æ±‡æ€»æ–‡ä»¶: {summary_filename}")
            print(f"ğŸ“Š æ€»æ–°é—»æ•°: {total_matched}")

            # è¯»å–æ–‡ä»¶ç»Ÿè®¡æ¶‰åŠè‚¡ç¥¨æ•°
            final_df = pd.read_csv(summary_filename, encoding='utf-8-sig')
            print(f"ğŸ“Š æ¶‰åŠè‚¡ç¥¨: {final_df['stock_code'].nunique()}")
        else:
            print(f"\nâš ï¸ æœªæŠ“å–åˆ°ä»»ä½•æ–°é—»æ•°æ®")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ—¶é—´æ®µæ–°é—»æŠ“å–å·¥å…·')
    parser.add_argument('--start_date', type=str, default='2022-01-01', help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end_date', type=str, default='2025-10-10', help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')

    args = parser.parse_args()

    # å¯¼å…¥é…ç½®
    import sys
    sys.path.append(str(Path(__file__).parent.parent / "config"))
    from api_config import TUSHARE_TOKEN

    print(f"ğŸ”‘ é…ç½®æ£€æŸ¥:")
    print(f"   - Tushare Token: {'å·²é…ç½®' if TUSHARE_TOKEN != 'your_tushare_token_here' else 'æœªé…ç½®'}")

    # åˆå§‹åŒ–æŠ“å–å™¨
    fetcher = PeriodNewsFetcher(TUSHARE_TOKEN)

    # æ‰§è¡ŒæŠ“å–
    fetcher.fetch_period_news(args.start_date, args.end_date)


if __name__ == "__main__":
    main()
