# 时间段新闻抓取工具使用说明

## 功能概述

`period_news_fetcher.py` 是一个基于原 `daily_news_analyzer_v2.py` 改造的新闻抓取工具，主要改进：

- ✅ **支持时间段抓取**：从单日抓取升级为时间段批量抓取
- ✅ **去除大模型分析**：专注于新闻数据采集，不进行LLM分析
- ✅ **自动过滤工作日**：自动跳过周末，只抓取交易日
- ✅ **多种输出模式**：支持按天保存、汇总保存或两者兼有
- ✅ **详细统计报告**：生成Markdown格式的汇总报告

## 主要功能

### 1. 新闻抓取
- 从Tushare获取指定时间段的新闻数据
- 自动匹配股票池中的相关股票
- 基于股票名称和代码进行关键词匹配

### 2. 数据输出
- **按天输出**：每天的新闻单独保存为CSV文件
- **汇总输出**：所有新闻合并为一个CSV文件
- **统计报告**：生成Markdown格式的分析报告

### 3. 统计分析
- 每日新闻数量统计
- 股票新闻分布（Top 20）
- 行业新闻分布（Top 10）

## 安装依赖

```bash
pip install tushare pandas
```

## 使用方法

### 基本用法

```bash
# 抓取指定时间段的新闻（默认输出模式：both）
python period_news_fetcher.py --start_date 2025-09-01 --end_date 2025-09-30
```

### 指定输出模式

```bash
# 只生成按天的文件
python period_news_fetcher.py --start_date 2025-09-01 --end_date 2025-09-30 --output_mode daily

# 只生成汇总文件
python period_news_fetcher.py --start_date 2025-09-01 --end_date 2025-09-30 --output_mode summary

# 两者都生成（默认）
python period_news_fetcher.py --start_date 2025-09-01 --end_date 2025-09-30 --output_mode both
```

## 参数说明

| 参数 | 必填 | 说明 | 示例 |
|------|------|------|------|
| `--start_date` | 是 | 开始日期 | 2025-09-01 |
| `--end_date` | 是 | 结束日期 | 2025-09-30 |
| `--output_mode` | 否 | 输出模式 | daily/summary/both (默认: both) |

## 输出文件说明

所有输出文件保存在 `D:/projects/q/myQ/output/period_news/` 目录下：

### 1. 按天新闻文件（output_mode=daily 或 both）
```
news_20250901.csv
news_20250902.csv
...
```
每个文件包含该日匹配到的股票相关新闻。

### 2. 汇总新闻文件（output_mode=summary 或 both）
```
summary_20250901_20250930.csv
```
包含整个时间段所有匹配的新闻数据。

### 3. 统计文件（始终生成）
```
stats_20250901_20250930.csv
```
每日新闻统计信息，包含：
- date: 日期
- total_news: 总新闻数
- matched_news: 匹配的新闻数
- matched_stocks: 涉及的股票数

### 4. 汇总报告（output_mode=summary 或 both）
```
report_20250901_20250930.md
```
Markdown格式的分析报告，包含：
- 每日统计表
- 股票新闻统计 Top 20
- 行业新闻分布 Top 10

## CSV 文件字段说明

### 新闻数据字段
- `datetime`: 新闻发布时间
- `title`: 新闻标题
- `content`: 新闻内容
- `stock_code`: 股票代码
- `stock_name`: 股票名称
- `industry`: 所属行业
- `matched_keyword`: 匹配的关键词
- `fetch_date`: 抓取日期

## 与原脚本的主要区别

| 特性 | daily_news_analyzer_v2.py | period_news_fetcher.py |
|------|--------------------------|------------------------|
| 抓取范围 | 单日 | 时间段（支持多天） |
| LLM分析 | ✅ 包含情感分析和评分 | ❌ 不包含（仅抓取） |
| 输出模式 | 固定格式 | 灵活（daily/summary/both） |
| 工作日过滤 | ❌ | ✅ 自动跳过周末 |
| 批量处理 | ❌ | ✅ 支持 |
| 执行成本 | 高（调用LLM API） | 低（仅调用Tushare） |

## 使用场景

1. **历史数据采集**：批量抓取过去一段时间的新闻数据
2. **数据预处理**：先抓取原始新闻，后续再决定是否需要分析
3. **成本控制**：避免频繁调用昂贵的LLM API
4. **数据存档**：定期备份新闻数据供后续分析

## 注意事项

1. **API限制**：Tushare可能有调用频率限制，脚本已添加1秒延迟
2. **数据完整性**：部分交易日可能没有新闻数据，这是正常情况
3. **配置文件**：确保 `D:/projects/q/myQ/config/api_config.py` 中配置了有效的 `TUSHARE_TOKEN`
4. **股票池**：确保 `D:/projects/q/myQ/config/stock_pool.json` 文件存在且格式正确

## 示例输出

```
🚀 开始抓取时间段新闻
   开始日期: 2025-09-01
   结束日期: 2025-09-30
   输出模式: both

📅 共需抓取 22 个交易日

============================================================
处理进度: [1/22] - 2025-09-01
============================================================
📰 获取新闻数据: 2025-09-01
   ✅ 获取到 156 条新闻
🔍 匹配新闻到股票...
🎯 匹配完成，找到 45 条股票相关新闻
   💾 当日结果已保存: D:\projects\q\myQ\output\period_news\news_20250901.csv

...

🎉 抓取完成！

📊 总体统计:
   - 交易日天数: 22
   - 总新闻数: 3420
   - 匹配新闻数: 876
   - 平均每日新闻: 39.8
   - 平均涉及股票: 25.4
```

## 常见问题

**Q: 为什么某些日期没有新闻？**
A: 这可能是因为：
- 该日期是周末或节假日（脚本会自动跳过周末）
- Tushare数据源该日确实没有新闻
- API调用失败

**Q: 如何修改抓取的时间范围（9:00-18:00）？**
A: 修改 `get_news_by_date()` 方法中的 `start_datetime` 和 `end_datetime` 参数。

**Q: 可以只抓取特定股票的新闻吗？**
A: 可以，修改 `stock_pool.json` 文件，只保留需要的股票即可。

## 后续开发建议

如果需要进一步扩展功能，可以考虑：
1. 添加去重功能（避免重复抓取）
2. 支持增量抓取（只抓取新增数据）
3. 添加数据库存储（替代CSV文件）
4. 支持多数据源（不仅限于新浪财经）
5. 添加可视化报表生成
