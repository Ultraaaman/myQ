{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b0d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "openrouter_key='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'\n",
    "response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": \"deepseek/deepseek-chat-v3.1:free\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"解释一下多因子策略在投资组合中的作用?用中文回答\"\n",
    "      }\n",
    "    ],\n",
    "    \n",
    "  })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20438999",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051846a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": {\n",
      "    \"message\": \"User not found.\",\n",
      "    \"code\": 401\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "openrouter_key='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'\n",
    "response = requests.get(\n",
    "  url=\"https://openrouter.ai/api/v1/key\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\"\n",
    "  }\n",
    ")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7ffd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_parquet(r'D:\\projects\\q\\data\\minute_data\\000002\\2025-09.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a471ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目路径\n",
    "sys.path.append(r'D:\\projects\\q\\myQ')\n",
    "from quantlib.market_data import get_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8909aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 601899: 获取A股数据失败 - '1d'\n"
     ]
    }
   ],
   "source": [
    "from quantlib.market_data import MarketDataManager\n",
    "manager = MarketDataManager()\n",
    "data = manager.get_stock_data('601899', market='CN', period='1mo', interval='1d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097af9a",
   "metadata": {},
   "source": [
    "ak.stock_news_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "340974a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请求URL: https://feed.mix.sina.com.cn/api/roll/get\n",
      "参数: {'pageid': 153, 'lid': 2516, 'k': '', 'num': 10, 'page': 1}\n",
      "\n",
      "状态码: 200\n",
      "响应长度: 20278\n",
      "\n",
      "JSON结构:\n",
      "顶级键: ['result']\n",
      "result键: ['status', 'timestamp', 'top', 'pdps', 'cre', 'total', 'end', 'start', 'lid', 'rtime', 'data']\n",
      "获取到 10 条新闻\n",
      "\n",
      "前3条新闻:\n",
      "\n",
      "新闻1:\n",
      "  字段: ['icons', 'is_cre_manual', 'hqChart', 'intime', 'channelid', 'ctime', 'mtime', 'authoruid', 'level', 'vid', 'ipad_vid', 'video_time_length', 'categoryid', 'mediaid', 'templateid', 'productid', 'ext_0', 'ext_1', 'ext_2', 'ext_3', 'ext_4', 'docid', 'url', 'urls', 'wapurl', 'wapurls', 'wapsummary', 'title', 'stitle', 'summary', 'intro', 'author', 'commentid', 'video_id', 'keywords', 'media_name', 'columnid', 'subjectid', 'img', 'images', 'lids', 'oid']\n",
      "  标题: 国金证券：首予中国生物制药“买入”评级 目标价11.25港元\n",
      "  URL: https://finance.sina.com.cn/tob/2025-09-23/doc-infrnksr7542561.shtml\n",
      "  时间: 1758609799\n",
      "  来源: \n",
      "\n",
      "新闻2:\n",
      "  字段: ['icons', 'is_cre_manual', 'hqChart', 'intime', 'channelid', 'ctime', 'mtime', 'authoruid', 'level', 'vid', 'ipad_vid', 'video_time_length', 'categoryid', 'mediaid', 'templateid', 'productid', 'ext_0', 'ext_1', 'ext_2', 'ext_3', 'ext_4', 'docid', 'url', 'urls', 'wapurl', 'wapurls', 'wapsummary', 'title', 'stitle', 'summary', 'intro', 'author', 'commentid', 'video_id', 'keywords', 'media_name', 'columnid', 'subjectid', 'img', 'images', 'lids', 'oid']\n",
      "  标题: 科净源（301372）被预处罚，股民索赔可期\n",
      "  URL: https://finance.sina.com.cn/stock/gmwq/rightscase/2025-09-23/doc-infrnekt7670081.shtml\n",
      "  时间: 1758609258\n",
      "  来源: \n",
      "\n",
      "新闻3:\n",
      "  字段: ['icons', 'is_cre_manual', 'hqChart', 'intime', 'channelid', 'ctime', 'mtime', 'authoruid', 'level', 'vid', 'ipad_vid', 'video_time_length', 'categoryid', 'mediaid', 'templateid', 'productid', 'ext_0', 'ext_1', 'ext_2', 'ext_3', 'ext_4', 'docid', 'url', 'urls', 'wapurl', 'wapurls', 'wapsummary', 'title', 'stitle', 'summary', 'intro', 'author', 'commentid', 'video_id', 'keywords', 'media_name', 'columnid', 'subjectid', 'img', 'images', 'lids', 'oid']\n",
      "  标题: 创意信息（300366）被预处罚，股民索赔可期\n",
      "  URL: https://finance.sina.com.cn/stock/gmwq/rightscase/2025-09-23/doc-infrnekn0671025.shtml\n",
      "  时间: 1758609239\n",
      "  来源: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 测试新浪财经新闻API\n",
    "url = \"https://feed.mix.sina.com.cn/api/roll/get\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'pageid': 153,\n",
    "    'lid': 2516,  # 财经新闻\n",
    "    'k': '',\n",
    "    'num': 10,\n",
    "    'page': 1\n",
    "}\n",
    "\n",
    "print(\"请求URL:\", url)\n",
    "print(\"参数:\", params)\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "print(\"\\n状态码:\", response.status_code)\n",
    "print(\"响应长度:\", len(response.text))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()\n",
    "        print(\"\\nJSON结构:\")\n",
    "        print(\"顶级键:\", list(data.keys()))\n",
    "        \n",
    "        if 'result' in data:\n",
    "            print(\"result键:\", list(data['result'].keys()))\n",
    "            \n",
    "            if 'data' in data['result']:\n",
    "                news_list = data['result']['data']\n",
    "                print(f\"获取到 {len(news_list)} 条新闻\")\n",
    "                \n",
    "                print(\"\\n前3条新闻:\")\n",
    "                for i, news in enumerate(news_list[:3]):\n",
    "                    print(f\"\\n新闻{i+1}:\")\n",
    "                    print(\"  字段:\", list(news.keys()))\n",
    "                    print(\"  标题:\", news.get('title', ''))\n",
    "                    print(\"  URL:\", news.get('url', ''))\n",
    "                    print(\"  时间:\", news.get('ctime', ''))\n",
    "                    print(\"  来源:\", news.get('media', ''))\n",
    "                    \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"不是JSON格式\")\n",
    "        print(\"前500字符:\", response.text[:500])\n",
    "else:\n",
    "    print(\"请求失败\")\n",
    "    print(\"响应内容:\", response.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99925c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索: 紫金矿业\n",
      "\n",
      "获取第1页...\n",
      "第1页找到 4 条新闻\n",
      "  ✓ 大行评级｜杰富瑞：维持紫金矿业“买入”评级 分拆紫金黄金国际有助释放价值...\n",
      "  ✓ 中国罕王：向紫金矿业配售融资2.35亿，拓澳洲金矿 | 港股再融资...\n",
      "  ✓ 中国罕王早盘涨超19% 折让14.7%向紫金矿业发行新股...\n",
      "  ✓ 紫金矿业涨2.01%，成交额11.13亿元，主力资金净流入1.14亿元...\n",
      "\n",
      "获取第2页...\n",
      "第2页找到 0 条新闻\n",
      "\n",
      "总共获取 4 条新闻\n",
      "\n",
      "=== 开始获取新闻内容 ===\n",
      "\n",
      "1. 获取内容: 大行评级｜杰富瑞：维持紫金矿业“买入”评级 分拆紫金黄金国际有助释放价值...\n",
      "   ✓ 成功 (348 字符)\n",
      "\n",
      "2. 获取内容: 中国罕王：向紫金矿业配售融资2.35亿，拓澳洲金矿 | 港股再融资...\n",
      "   ✓ 成功 (441 字符)\n",
      "\n",
      "3. 获取内容: 中国罕王早盘涨超19% 折让14.7%向紫金矿业发行新股...\n",
      "   ✓ 成功 (435 字符)\n",
      "\n",
      "=== 结果 ===\n",
      "获得 3 条有效新闻\n",
      "已保存到 sina_test_news.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def get_sina_search_news(stock_name, max_pages=3):\n",
    "    \"\"\"从新浪搜索获取个股新闻\"\"\"\n",
    "    print(f\"搜索: {stock_name}\")\n",
    "    \n",
    "    search_url = \"https://search.sina.com.cn/news\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    \n",
    "    all_news = []\n",
    "    \n",
    "    for page in range(1, max_pages + 1):\n",
    "        print(f\"\\n获取第{page}页...\")\n",
    "        \n",
    "        params = {\n",
    "            'q': stock_name,\n",
    "            'c': 'news', \n",
    "            'from': 'index',\n",
    "            'page': page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(search_url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # 找到所有财经新闻链接\n",
    "                all_links = soup.find_all('a', href=True)\n",
    "                page_news = []\n",
    "                \n",
    "                for link in all_links:\n",
    "                    href = link.get('href', '')\n",
    "                    if 'finance.sina.com.cn' in href:\n",
    "                        title = link.get_text().strip()\n",
    "                        if title and len(title) > 10:\n",
    "                            # 避免重复\n",
    "                            if not any(news['title'] == title for news in all_news):\n",
    "                                news_item = {\n",
    "                                    'title': title,\n",
    "                                    'url': href,\n",
    "                                    'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                    'source': '新浪财经'\n",
    "                                }\n",
    "                                page_news.append(news_item)\n",
    "                                all_news.append(news_item)\n",
    "                \n",
    "                print(f\"第{page}页找到 {len(page_news)} 条新闻\")\n",
    "                for news in page_news:\n",
    "                    print(f\"  ✓ {news['title'][:50]}...\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"第{page}页获取失败: {e}\")\n",
    "    \n",
    "    print(f\"\\n总共获取 {len(all_news)} 条新闻\")\n",
    "    return all_news\n",
    "\n",
    "def get_news_content(url):\n",
    "    \"\"\"获取新闻内容\"\"\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.encoding = 'utf-8'\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='utf-8')\n",
    "            \n",
    "            # 移除无用标签\n",
    "            for tag in soup(['script', 'style', 'iframe']):\n",
    "                tag.decompose()\n",
    "            \n",
    "            # 尝试常见的内容选择器\n",
    "            selectors = ['#artibody', '.article-body', '.article-content', '#article_content']\n",
    "            \n",
    "            for selector in selectors:\n",
    "                content_div = soup.select_one(selector)\n",
    "                if content_div:\n",
    "                    text = content_div.get_text(separator=' ', strip=True)\n",
    "                    if len(text) > 100:\n",
    "                        return text[:2000]  # 限制长度\n",
    "            \n",
    "            # 备用方案：获取段落\n",
    "            paragraphs = soup.find_all('p')\n",
    "            if paragraphs:\n",
    "                content = ' '.join([p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20])\n",
    "                if len(content) > 100:\n",
    "                    return content[:2000]\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"获取内容失败: {e}\")\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "# 测试函数\n",
    "def test_sina_news():\n",
    "    \"\"\"测试获取新闻\"\"\"\n",
    "    stock_name = \"紫金矿业\"\n",
    "    \n",
    "    # 获取新闻列表\n",
    "    news_list = get_sina_search_news(stock_name, max_pages=2)\n",
    "    \n",
    "    if news_list:\n",
    "        print(f\"\\n=== 开始获取新闻内容 ===\")\n",
    "        \n",
    "        # 获取每条新闻的内容\n",
    "        for i, news in enumerate(news_list[:3], 1):  # 只处理前3条测试\n",
    "            print(f\"\\n{i}. 获取内容: {news['title'][:50]}...\")\n",
    "            content = get_news_content(news['url'])\n",
    "            \n",
    "            if content:\n",
    "                news['content'] = f\"{news['title']}\\n\\n{content}\"\n",
    "                print(f\"   ✓ 成功 ({len(content)} 字符)\")\n",
    "            else:\n",
    "                print(f\"   ✗ 失败\")\n",
    "        \n",
    "        # 转为DataFrame\n",
    "        df_data = []\n",
    "        for news in news_list[:3]:\n",
    "            if 'content' in news:\n",
    "                df_data.append({\n",
    "                    'date': news['date'],\n",
    "                    'content': news['content']\n",
    "                })\n",
    "        \n",
    "        if df_data:\n",
    "            df = pd.DataFrame(df_data)\n",
    "            print(f\"\\n=== 结果 ===\")\n",
    "            print(f\"获得 {len(df)} 条有效新闻\")\n",
    "            \n",
    "            # 保存测试\n",
    "            df.to_csv('sina_test_news.csv', index=False, encoding='utf-8-sig')\n",
    "            print(\"已保存到 sina_test_news.csv\")\n",
    "            \n",
    "            return df\n",
    "    \n",
    "    return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sina_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b966bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts \n",
    "pro = ts.pro_api()\n",
    "\n",
    "\n",
    "#提取新闻内容\n",
    "df = pro.news(src='sina', start_date='2025-09-23 10:00:00', end_date='2025-09-23 10:59:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e7c1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "搜索关键词: 紫金矿业\n",
      "时间范围: 2025-09-20 到 2025-09-23\n",
      "查询时段: 2025-09-20 00:00:00 - 2025-09-20 01:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 01:00:00 - 2025-09-20 02:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 02:00:00 - 2025-09-20 03:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 03:00:00 - 2025-09-20 04:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 04:00:00 - 2025-09-20 05:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 05:00:00 - 2025-09-20 06:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 06:00:00 - 2025-09-20 07:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 07:00:00 - 2025-09-20 08:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 08:00:00 - 2025-09-20 09:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 09:00:00 - 2025-09-20 10:00:00\n",
      "  无相关新闻\n",
      "查询时段: 2025-09-20 10:00:00 - 2025-09-20 11:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 11:00:00 - 2025-09-20 12:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 12:00:00 - 2025-09-20 13:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 13:00:00 - 2025-09-20 14:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 14:00:00 - 2025-09-20 15:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 15:00:00 - 2025-09-20 16:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 16:00:00 - 2025-09-20 17:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 17:00:00 - 2025-09-20 18:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 18:00:00 - 2025-09-20 19:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 19:00:00 - 2025-09-20 20:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 20:00:00 - 2025-09-20 21:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 21:00:00 - 2025-09-20 22:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 22:00:00 - 2025-09-20 23:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-20 23:00:00 - 2025-09-21 00:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 00:00:00 - 2025-09-21 01:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 01:00:00 - 2025-09-21 02:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 02:00:00 - 2025-09-21 03:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 03:00:00 - 2025-09-21 04:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 04:00:00 - 2025-09-21 05:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 05:00:00 - 2025-09-21 06:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 06:00:00 - 2025-09-21 07:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 07:00:00 - 2025-09-21 08:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 08:00:00 - 2025-09-21 09:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 09:00:00 - 2025-09-21 10:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 10:00:00 - 2025-09-21 11:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 11:00:00 - 2025-09-21 12:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 12:00:00 - 2025-09-21 13:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 13:00:00 - 2025-09-21 14:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 14:00:00 - 2025-09-21 15:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 15:00:00 - 2025-09-21 16:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 16:00:00 - 2025-09-21 17:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 17:00:00 - 2025-09-21 18:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 18:00:00 - 2025-09-21 19:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 19:00:00 - 2025-09-21 20:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 20:00:00 - 2025-09-21 21:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 21:00:00 - 2025-09-21 22:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 22:00:00 - 2025-09-21 23:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-21 23:00:00 - 2025-09-22 00:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 00:00:00 - 2025-09-22 01:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 01:00:00 - 2025-09-22 02:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 02:00:00 - 2025-09-22 03:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 03:00:00 - 2025-09-22 04:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 04:00:00 - 2025-09-22 05:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 05:00:00 - 2025-09-22 06:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 06:00:00 - 2025-09-22 07:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 07:00:00 - 2025-09-22 08:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 08:00:00 - 2025-09-22 09:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 09:00:00 - 2025-09-22 10:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 10:00:00 - 2025-09-22 11:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 11:00:00 - 2025-09-22 12:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 12:00:00 - 2025-09-22 13:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 13:00:00 - 2025-09-22 14:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 14:00:00 - 2025-09-22 15:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 15:00:00 - 2025-09-22 16:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 16:00:00 - 2025-09-22 17:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 17:00:00 - 2025-09-22 18:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 18:00:00 - 2025-09-22 19:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 19:00:00 - 2025-09-22 20:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 20:00:00 - 2025-09-22 21:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 21:00:00 - 2025-09-22 22:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 22:00:00 - 2025-09-22 23:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "查询时段: 2025-09-22 23:00:00 - 2025-09-23 00:00:00\n",
      "  查询失败: 抱歉，您每分钟最多访问该接口10次，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。\n",
      "\n",
      "未找到相关新闻\n",
      "未获取到数据\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "def get_stock_news(keyword, start_date, end_date, pro_api=None):\n",
    "    \"\"\"\n",
    "    从tushare获取包含关键词的新闻\n",
    "    \n",
    "    Args:\n",
    "        keyword: 搜索关键词\n",
    "        start_date: 开始日期 '2025-01-01'\n",
    "        end_date: 结束日期 '2025-09-23'  \n",
    "        pro_api: tushare pro接口，如果为None则自动创建\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 包含date和content的新闻数据\n",
    "    \"\"\"\n",
    "    if pro_api is None:\n",
    "        pro_api = ts.pro_api()\n",
    "    \n",
    "    print(f\"搜索关键词: {keyword}\")\n",
    "    print(f\"时间范围: {start_date} 到 {end_date}\")\n",
    "    \n",
    "    # 转换日期格式\n",
    "    start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    all_news = []\n",
    "    current_dt = start_dt\n",
    "    \n",
    "    while current_dt < end_dt:\n",
    "        # 每次查询1小时\n",
    "        next_dt = current_dt + timedelta(hours=1)\n",
    "        if next_dt > end_dt:\n",
    "            next_dt = end_dt\n",
    "        \n",
    "        start_str = current_dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = next_dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"查询时段: {start_str} - {end_str}\")\n",
    "        \n",
    "        try:\n",
    "            # 调用tushare接口\n",
    "            df = pro_api.news(\n",
    "                src='sina', \n",
    "                start_date=start_str, \n",
    "                end_date=end_str\n",
    "            )\n",
    "            \n",
    "            if not df.empty:\n",
    "                # 在content列搜索关键词\n",
    "                mask = df['content'].str.contains(keyword, na=False)\n",
    "                filtered_df = df[mask]\n",
    "                \n",
    "                if not filtered_df.empty:\n",
    "                    print(f\"  找到 {len(filtered_df)} 条相关新闻\")\n",
    "                    all_news.append(filtered_df)\n",
    "                else:\n",
    "                    print(f\"  无相关新闻\")\n",
    "            else:\n",
    "                print(f\"  无新闻数据\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  查询失败: {e}\")\n",
    "        \n",
    "        # 移动到下一个时间段\n",
    "        current_dt = next_dt\n",
    "    \n",
    "    # 合并所有结果\n",
    "    if all_news:\n",
    "        result_df = pd.concat(all_news, ignore_index=True)\n",
    "        \n",
    "        # 去重（基于title和datetime）\n",
    "        result_df = result_df.drop_duplicates(subset=['title', 'datetime'])\n",
    "        \n",
    "        # 只保留需要的列\n",
    "        final_df = result_df[['datetime', 'content']].copy()\n",
    "        final_df.columns = ['date', 'content']\n",
    "        \n",
    "        # 按时间排序\n",
    "        final_df = final_df.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n总共获取 {len(final_df)} 条去重后的相关新闻\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"\\n未找到相关新闻\")\n",
    "        return pd.DataFrame(columns=['date', 'content'])\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化tushare\n",
    "    pro = ts.pro_api()\n",
    "    \n",
    "    # 获取紫金矿业相关新闻\n",
    "    df = get_stock_news(\n",
    "        keyword=\"紫金矿业\",\n",
    "        start_date=\"2025-09-20\", \n",
    "        end_date=\"2025-09-23\",\n",
    "        pro_api=pro\n",
    "    )\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(\"\\n=== 结果预览 ===\")\n",
    "        print(f\"数据形状: {df.shape}\")\n",
    "        print(f\"时间范围: {df['date'].min()} 到 {df['date'].max()}\")\n",
    "        \n",
    "        print(\"\\n前3条新闻:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            print(f\"\\n{i+1}. 时间: {row['date']}\")\n",
    "            print(f\"   内容: {row['content'][:150]}...\")\n",
    "        \n",
    "        # 保存结果\n",
    "        df.to_csv('tushare_news.csv', index=False, encoding='utf-8-sig')\n",
    "        print(\"\\n数据已保存到 tushare_news.csv\")\n",
    "    else:\n",
    "        print(\"未获取到数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f36971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
